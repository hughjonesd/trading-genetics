---
title: "Model proofs"
output: 
  bookdown::pdf_document2:
    toc: false
    latex_engine: xelatex
    number_sections: false
    keep_tex: true
header-includes:
  - \usepackage{subfig}
  - \usepackage{setspace}\doublespacing
  - \usepackage{amsmath}
  - \usepackage{amsfonts}
  - \usepackage{amsthm}
  - \usepackage{mitpress}
  - \newtheorem{prop}{Proposition}
  - \newtheorem{claim}{Claim}
---

\begin{proof}[Proof of Proposition \ref{prop-couples-SGAM}]

By a change of variable, rewrite:

\[
\left( 
\begin{array}{c}
x_{1} \\ 
x_{2}%
\end{array}%
\right) \rightarrow \left( 
\begin{array}{c}
x_{1} \\ 
u%
\end{array}%
\right) \text{ where }u=\frac{ax_{1}+\left( 1-a\right) x_{2}}{\sqrt{%
a^{2}s^{2}+\left( 1-a\right) ^{2}S^{2}+2a\left( 1-a\right) \sigma }}=
\frac{ax_{1}+\left( 1-a\right) x_{2}}{\sigma_I}
\]
is the attractiveness rescaled to $\mathcal{N}(0, 1)$. Thus,
\[
\left( 
\begin{array}{c}
x_{1} \\ 
u
\end{array}
\right) = \left( 
\begin{array}{cc}
1 & 0 \\ 
a/\sigma_I & (1-a)/\sigma_I%
\end{array}%
\right) \left( 
\begin{array}{c}
x_{1} \\ 
x_{2}%
\end{array}%
\right). 
\]


Note that the means are still zero, but the covariance of $(x_1,u)$ is:

\begin{eqnarray*}
C\left( 
\begin{array}{c}
x_{1} \\ 
u
\end{array}
\right) &=&\left( 
\begin{array}{cc}
1 & 0 \\ 
a/\sigma_I & \left( 1-a\right)/\sigma_I%
\end{array}%
\right) \left( 
\begin{array}{cc}
s^{2} & \sigma \\ 
\sigma & S^{2}%
\end{array}%
\right) \left( 
\begin{array}{cc}
1 & a/\sigma_I \\ 
0 & \left( 1-a\right)/\sigma_I%
\end{array}%
\right) \\
&=&\left( 
\begin{array}{cc}
s^{2} &  \left( as^{2}+\sigma \left( 1-a\right) \right)/\sigma_I \\ 
\left( as^{2}+\sigma \left( 1-a\right) \right)/\sigma_I & 1%
\end{array}%
\right) \allowbreak 
\end{eqnarray*}


Under SGAM, individual $\left( 
\begin{array}{c}
x_{1} \\ 
u
\end{array} 
\right)$ is matched with $\left( 
\begin{array}{c}
y_{1} \\ 
v%
\end{array}%
\right)$ such that $u = v = t$.

The distribution of $t$ is 
$\mathcal{N}\left( 0,1\right)$. Therefore the vector $\left( 
\begin{array}{c}
x_{1} \\ 
y_{1} \\ 
t%
\end{array}%
\right)$ is normally distributed, with mean 0, and covariance
\[
\Sigma =\left( 
\begin{array}{ccc}
s^{2} & d^{2} & d \\ 
d^{2} & s^{2} & d \\ 
d & d & 1%
\end{array}%
\right) \allowbreak 
\]
where
\[
d=\frac{as^{2}+\left( 1-a\right) \sigma }{\sqrt{S^{2}\left( a-1\right)
^{2}+a^{2}s^{2}-2a\sigma \left( a-1\right) }} = 
\frac{as^{2}+\left( 1-a\right) \sigma }{\sigma_I}
\]

Finally, we are interested in 
\[
\left( 
\begin{array}{c}
x_{1} \\ 
x_{2} \\ 
y_{1} \\ 
y_{2}%
\end{array}%
\right) =\left( 
\begin{array}{ccc}
1 & 0 & 0 \\ 
-\frac{a}{1-a} & 0 & \frac{\sigma_I}{1-a} \\ 
0 & 1 & 0 \\ 
0 & -\frac{a}{1-a} & \frac{\sigma_I}{1-a}%
\end{array}%
\right) \left( 
\begin{array}{c}
x_{1} \\ 
y_{1} \\ 
t%
\end{array}%
\right) 
\]%
therefore again the means are 0 and 
\begin{eqnarray*}
\mathbb{C}\left( 
\begin{array}{c}
x_{1} \\ 
x_{2} \\ 
y_{1} \\ 
y_{2}%
\end{array}%
\right) &=&\left( 
\begin{array}{ccc}
1 & 0 & 0 \\ 
-\frac{a}{1-a} & 0 & \frac{\sigma_I}{1-a} \\ 
0 & 1 & 0 \\ 
0 & -\frac{a}{1-a} & \frac{\sigma_I}{1-a}%
\end{array}%
\right) \Sigma \left( 
\begin{array}{ccc}
1 & 0 & 0 \\ 
-\frac{a}{1-a} & 0 & \frac{\sigma_I}{1-a} \\ 
0 & 1 & 0 \\ 
0 & -\frac{a}{1-a} & \frac{\sigma_I}{1-a}%
\end{array}%
\right) ^{T} \\
&=&\allowbreak \left( 
\begin{array}{cccc}
s^{2} & \sigma & A^{2} & AC \\ 
\sigma & S^{2} & AC & C^{2} \\ 
A^{2} & AC & s^{2} & \sigma \\ 
AC & C^{2} & \sigma & S^{2}%
\end{array}%
\right) \allowbreak
\end{eqnarray*}%
where:%
\begin{eqnarray*}
A &=&\frac{as^{2}+\left( 1-a\right) \sigma }{\sigma_I}\text{ \ and} \\
C &=&\frac{a\sigma +\left( 1-a\right) S^{2}}{\sigma_I}.
\end{eqnarray*}



\end{proof}



\begin{proof}[Proof of Claim \ref{claim-E-children-RM}]


Under RM, the joint distribution of $\left( \frac{\tau }{2}\left(
x_{1}+y_{1}\right) +\varepsilon ,x_{2},y_{2}\right) $ is normal with mean $%
\left( 0,0,0\right) $ and covariance$\allowbreak $%
\[
C=\left( 
\begin{array}{lcr}
\frac{\tau ^{2}}{2}\left( s^{2}+\sigma \right) +1 & \frac{\tau }{2}\sigma  & 
\frac{\tau }{2}\sigma  \\ 
\frac{\tau }{2}\sigma  & S^{2} & 0 \\ 
\frac{\tau }{2}\sigma  & 0 & S^{2}%
\end{array}%
\right) 
\]%
Therefore%
\begin{eqnarray*}
\mathbb{E}\left[ \frac{\tau }{2}\left( x_{1}+y_{1}\right) +\varepsilon \mid
x_{2}=v,y_{2}=w\right]  &=&\left( 
\begin{array}{rr}
\frac{\tau }{2}\sigma  & \frac{\tau }{2}\sigma 
\end{array}%
\right) \left( 
\begin{array}{rr}
S^{2} & 0 \\ 
0 & S^{2}%
\end{array}%
\right) ^{-1}\left( 
\begin{array}{r}
v \\ 
w%
\end{array}%
\right)  \\
&=&\frac{\sigma \tau }{2S^{2}}\left( v+w\right) 
\end{eqnarray*}

In particular, if $\sigma =0$, this expectation is equal to 0.
\end{proof}


\begin{proof}[Proof of Claim \ref{claim-E-children-SGAM}]

From \eqref{cov-children-SGAM}, the joint distribution of $\left( \frac{\tau }{2}\left(
x_{1}+y_{1}\right) +\varepsilon ,x_{2},y_{2}\right) $ is normal with mean $%
\left( 0,0,0\right) $ and covariance$\allowbreak $%
\[
\Sigma =\left( 
\begin{array}{rrr}
\frac{1}{2}\tau ^{2}\left( A^{2}+s^{2}\right) +1 & \frac{\tau }{2}\left(
\sigma +AC\right)  & \frac{\tau }{2}\left( \sigma +AC\right)  \\ 
\frac{\tau }{2}\left( \sigma +AC\right)  & S^{2} & C^{2} \\ 
\frac{\tau }{2}\left( \sigma +AC\right)  & C^{2} & S^{2}%
\end{array}%
\right) 
\]%
Therefore
\begin{eqnarray}
\mathbb{E}\left[ \frac{\tau }{2}\left( x_{1}+y_{1}\right) +\varepsilon \mid
x_{2}=v,y_{2}=w\right]  &=&\left( 
\begin{array}{rr}
\frac{\tau }{2}\left( \sigma +AC\right)  & \frac{\tau }{2}\left( \sigma
+AC\right) 
\end{array}%
\right) \left( 
\begin{array}{rr}
S^{2} & C^{2} \\ 
C^{2} & S^{2}%
\end{array}%
\right) ^{-1}\left( 
\begin{array}{r}
v \\ 
w%
\end{array}%
\right)   \nonumber \\
&=&\frac{1}{2}\tau \frac{\sigma +AC}{C^{2}+S^{2}}\left( v+w\right) 
\label{P1}
\end{eqnarray}%
In particular, if $\sigma =0$, we have%
\begin{eqnarray*}
A &=&\frac{as^{2}}{\sqrt{a^{2}s^{2}+\left( 1-a\right) ^{2}S^{2}}}\textrm{ \ and%
} \\
C &=&\frac{\left( 1-a\right) S^{2}}{\sqrt{a^{2}s^{2}+\left( 1-a\right)
^{2}S^{2}}},
\end{eqnarray*}%
and (\ref{P1}) becomes 
\begin{eqnarray*}
\mathbb{E}\left[ \frac{\tau }{2}\left( x_{1}+y_{1}\right) +\varepsilon \mid
x_{2}=v,y_{2}=w\right]  &=&\frac{1}{2}\tau \frac{a\left( 1-a\right) s^{2}}{%
a^{2}s^{2}+2\left( 1-a\right) ^{2}S^{2}}\left( v+w\right)  \\
&=&\frac{1}{2}\tau \frac{a\left( 1-a\right) \lambda }{a^{2}\lambda +2\left(
1-a\right) ^{2}}\left( v+w\right) 
\end{eqnarray*}
where $\lambda =s^{2}/S^{2}$ is the ratio of genetic variance to wealth variance.
The coefficient $\frac{a\left( 1-a\right) \lambda }{a^{2}\lambda +2\left(
1-a\right) ^{2}}$ is increasing, then decreasing in $a$ and is 0 for $a =  0$ or $a = 1$.
\end{proof}



\begin{proof}[Proof of Claim \ref{claim-corr-children-RM}]

Under RM, the covariance matrix for children's characteristics is:%
\begin{eqnarray*}
\mathbb{C} &=&\left( 
\begin{array}{cc}
1 & 0 \\ 
0 & 1%
\end{array}%
\right) +\left( 
\begin{array}{cccc}
\frac{\tau }{2} & 0 & \frac{\tau }{2} & 0 \\ 
0 & \frac{\theta }{2} & 0 & \frac{\theta }{2}%
\end{array}%
\right) \allowbreak \left( 
\begin{array}{cccc}
s^{2} & \sigma & 0 & 0 \\ 
\sigma & S^{2} & 0 & 0 \\ 
0 & 0 & s^{2} & \sigma \\ 
0 & 0 & \sigma & S^{2}%
\end{array}%
\right) \allowbreak \left( 
\begin{array}{cc}
\frac{1}{2}\tau & 0 \\ 
0 & \frac{1}{2}\theta \\ 
\frac{1}{2}\tau & 0 \\ 
0 & \frac{1}{2}\theta%
\end{array}%
\right) \\
&=&\left( 
\begin{array}{cc}
\frac{1}{2}s^{2}\tau ^{2}+1 & \frac{1}{2}\theta \sigma \tau \\ 
\frac{1}{2}\theta \sigma \tau & \frac{1}{2}S^{2}\theta ^{2}+1%
\end{array}%
\right)
\end{eqnarray*}%
so that the correlation between characteristics for children is: 
\[
Corr\left( x_{1}^{\prime },x_{2}^{\prime }\right) =\frac{\frac{1}{2}\theta
\sigma \tau }{\sqrt{\frac{1}{2}\tau ^{2}s^{2}+1}\sqrt{\frac{1}{2}\theta
^{2}S^{2}+1}} 
\]

Note that $\sigma =0$ gives a zero correlation for children as well. 
Also, because $\theta < 1$ and $\tau < 1$, the correlation is less than the 
parents' correlation of $\sigma/sS$.

\end{proof}


\begin{proof}[Proof of Claim \ref{claim-corr-children-SGAM}]

Again applying \eqref{cov-children-SGAM}, under SGAM, the correlation between 
children's traits is:
\[
Corr\left( x_{1}^{\prime },x_{2}^{\prime }\right) =\frac{\frac{1}{2}\theta
\tau \left( \sigma +AC\right) }{\sqrt{\frac{1}{2}\tau ^{2}\left(
A^{2}+s^{2}\right) +1}\sqrt{\frac{1}{2}\theta ^{2}\left( C^{2}+S^{2}\right)
+1}} 
\]
This is positive if $\sigma = 0$ so long as $AC > 0$ i.e. $0 < a < 1$. To show
it is increasing in $\theta$, strip out constant terms and take the derivative of
\[
\frac{\theta}{\sqrt{\frac{1}{2}\theta^2(C^2+S^2) + 1}}
\]
The derivative is signed by
\begin{align*}
& \left(\frac{1}{2}\theta^2(C^2+S^2) + 1\right)^{0.5} -
\frac{1}{2}\theta^2(C^2+S^2)\left(\frac{1}{2}\theta^2(C^2+S^2) + 1\right)^{-0.5} \\
>& \left(\frac{1}{2}\theta^2(C^2+S^2) + 1\right)^{0.5} - 
\left(\frac{1}{2}\theta^2(C^2+S^2)  + 1\right)\left(\frac{1}{2}\theta^2(C^2+S^2) + 1\right)^{-0.5} \\
=&\ 0.
\end{align*}
\end{proof}


\begin{proof}[Proof of Proposition \ref{prop-asymptotics-RM}]

The fixed point condition on the covariance matrix is
\[
\left( 
\begin{array}{cc}
s^{2} & \sigma  \\ 
\sigma  & S^{2}%
\end{array}%
\right) =\left( 
\begin{array}{cc}
\frac{1}{2}s^{2}\tau ^{2}+1 & \frac{1}{2}\theta \sigma \tau  \\ 
\frac{1}{2}\theta \sigma \tau  & \frac{1}{2}S^{2}\theta ^{2}+1%
\end{array}%
\right) 
\]
which gives
\[
s^{2}=\frac{2}{2-\tau ^{2}},S^{2}=\frac{2}{2-\theta ^{2}},\sigma =0.
\]

The asymptotic conditional expectation of children's genetics given parental SES is:

\[
\mathbb{E}\left[ \frac{\tau }{2}\left( x_{1}+y_{1}\right) +\varepsilon \mid
x_{2}=v,y_{2}=w\right] =0
\]%

since the traits $x_1,x_2,y_1,y_2$ are uncorrelated.

\end{proof}


\begin{proof}[Proof of Proposition \ref{prop-asymptotics-SGAM}]
Start by characterizing the invariant distribution. This must satisfy:%
\[
\left( 
\begin{array}{cc}
\bar{s}^{2} & \bar{\sigma} \\ 
\bar{\sigma} & \bar{S}^{2}%
\end{array}%
\right) =\left( 
\begin{array}{cc}
\frac{1}{2}\tau ^{2}\left( \bar{A}^{2}+\bar{s}^{2}\right) +1 & \frac{1}{2}%
\theta \tau \left( \bar{\sigma}+\bar{A}\bar{C}\right)  \\ 
\frac{1}{2}\theta \tau \left( \bar{\sigma}+\bar{A}\bar{C}\right)  & \frac{1}{%
2}\theta ^{2}\left( \bar{C}^{2}+\bar{S}^{2}\right) +1%
\end{array}%
\right) \allowbreak 
\]%
where%
\begin{eqnarray*}
\bar{A} &=&\frac{a\bar{s}^{2}+\left( 1-a\right) \bar{\sigma}}{\sqrt{a^{2}%
\bar{s}^{2}+\left( 1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma%
}}}\textrm{ \ and} \\
\bar{C} &=&\frac{a\bar{\sigma}+\left( 1-a\right) \bar{S}^{2}}{\sqrt{a^{2}%
\bar{s}^{2}+\left( 1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma%
}}},
\end{eqnarray*}%
Therefore%
\begin{eqnarray}
\bar{s}^{2} &=&\frac{1}{2}\tau ^{2}\left( \frac{\left( a\bar{s}^{2}+\left(
1-a\right) \bar{\sigma}\right) ^{2}}{a^{2}\bar{s}^{2}+\left( 1-a\right) ^{2}%
\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma}}+\bar{s}^{2}\right) +1 
\nonumber \\
\bar{S}^{2} &=&\frac{1}{2}\theta ^{2}\left( \frac{\left( a\bar{\sigma}%
+\left( 1-a\right) \bar{S}^{2}\right) ^{2}}{a^{2}\bar{s}^{2}+\left(
1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma}}+\bar{S}%
^{2}\right) +1  \label{FP} \\
\left( 1-\frac{1}{2}\theta \tau \right) \bar{\sigma} &=&\frac{1}{2}\theta
\tau \frac{\left( a\bar{\sigma}+\left( 1-a\right) \bar{S}^{2}\right) \left( a%
\bar{s}^{2}+\left( 1-a\right) \bar{\sigma}\right) }{a^{2}\bar{s}^{2}+\left(
1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma}}  \nonumber
\end{eqnarray}%
Define%
\[
\lambda =\bar{s}^{2}/\bar{S}^{2}\textrm{ and }\mu =\bar{\sigma}/\bar{S}^{2}
\]%
The last equation gives%
\[
\left( 1-\frac{1}{2}\theta \tau \right) \mu =\frac{1}{2}\theta \tau \frac{%
\left( a\mu +\left( 1-a\right) \right) \left( a\lambda +\left( 1-a\right)
\mu \right) }{a^{2}\lambda +\left( 1-a\right) ^{2}+2a\left( 1-a\right) \mu }
\]%
which is linear in $\lambda $; therefore%
\begin{equation}
\lambda =\frac{\mu \left( \frac{1}{2}\theta \tau -1\right) \left( \left(
a-1\right) ^{2}-2a\mu \left( a-1\right) \right) -\frac{1}{2}\theta \tau \mu
\left( a-1\right) \left( -a+a\mu +1\right) }{a^{2}\mu \left( 1-\frac{1}{2}%
\theta \tau \right) -\frac{1}{2}a\theta \tau \left( 1-a+a\mu \right) }
\label{Lamb}
\end{equation}

The first two give:%
\begin{align*}
& 1-\frac{1}{2}\theta ^{2}\left( \frac{\left( a\mu +\left( 1-a\right) \right)
^{2}}{a^{2}\bar{s}^{2}+\left( 1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) 
\bar{\sigma}}+1\right) \\
= & \lambda -\frac{1}{2}\tau ^{2}\left( \frac{\left(
a\lambda +\left( 1-a\right) \mu \right) ^{2}}{a^{2}\bar{s}^{2}+\left(
1-a\right) ^{2}\bar{S}^{2}+2a\left( 1-a\right) \bar{\sigma}}+\lambda \right) 
\end{align*}

where $\lambda $ is given by (\ref{Lamb}). This is equivalent to $F(\mu) =0$, 
where 

\begin{align*}
F\left( \mu \right) =& \lambda - \frac{1}{2}\tau ^{2}\left( \frac{\left(
a\lambda +\left( 1-a\right) \mu \right) ^{2}}{a^{2}\lambda +\left(
1-a\right) ^{2}+2a\left( 1-a\right) \mu }+\lambda \right) - \\
& \left( 1-\frac{1}{%
2}\theta ^{2}\left( \frac{\left( a\mu +\left( 1-a\right) \right) ^{2}}{%
a^{2}\lambda +\left( 1-a\right) ^{2}+2a\left( 1-a\right) \mu }+1\right)
\right)
\end{align*}

This equation is quadratic in $\mu $; thus it has two closed form solutions,
of which one, denoted $\phi \left( a,\theta ,\tau \right) $, is positive.
Then
\begin{align*}
\lambda =& \psi \left( a,\theta ,\tau \right) \\
 =& \frac{\phi \left( a,\theta
,\tau \right) \left( \frac{1}{2}\theta \tau -1\right) \left( \left(
a-1\right) ^{2}-2a\phi \left( a,\theta ,\tau \right) \left( a-1\right)
\right) -\frac{1}{2}\theta \tau \phi \left( a,\theta ,\tau \right) \left(
a-1\right) \left( -a+a\phi \left( a,\theta ,\tau \right) +1\right) }{%
a^{2}\phi \left( a,\theta ,\tau \right) \left( 1-\frac{1}{2}\theta \tau
\right) -\frac{1}{2}a\theta \tau \left( 1-a+a\phi \left( a,\theta ,\tau
\right) \right) } 
\end{align*}

Finally, the second equation in (\ref{FP}) gives
\[
1=\frac{1}{2}\theta ^{2}\left( \frac{\left( a\phi \left( a,\theta ,\tau
\right) +\left( 1-a\right) \right) ^{2}}{a^{2}\psi \left( a,\theta ,\tau
\right) +\left( 1-a\right) ^{2}+2a\left( 1-a\right) \phi \left( a,\theta
,\tau \right) }+1\right) +\frac{1}{\bar{S}^{2}}
\]%
which gives $\bar{S}^{2}$, then $\bar{s}^{2}$ and $\bar{\sigma}$ follow.
\end{proof}


\begin{proof}[Proof of Claim \ref{claim-men-women-different}]

Since men and women have different distributions of attractiveness,
we have to match them by quantiles of their respective distributions. 
Men's and women's attractiveness are distributed
\begin{align*}
N(0,\sigma_{I}^{2})\textrm{ where }\sigma_{I} & =\sqrt{a^{2}s^{2}+(1-a)^{2}S^{2}+2a(1-a)\sigma};\\
N(0,\sigma_{J}^{2})\textrm{ where }\sigma_{J} & =\sqrt{b^{2}s^{2}+(1-b)^{2}S^{2}+2b(1-b)\sigma}.
\end{align*}
Thus, men with normalized attractiveness $i(x)/\sigma_{I}$ match
women with normalized attractiveness $j(y)/\sigma_{J}$.

Change variables so that 
\begin{align*}
\left(\begin{array}{c}
x_{1}\\
x_{2}
\end{array}\right) & \rightarrow\left(\begin{array}{c}
x_{1}\\
u
\end{array}\right)\textrm{ where }u=\frac{ax_{1}+(1-a)x_{2}}{\sigma_{I}};\\
\left(\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right) & \rightarrow\left(\begin{array}{c}
y_{1}\\
v
\end{array}\right)\textrm{ where }v=\frac{by_{1}+(1-b)y_{2}}{\sigma_{J}}.
\end{align*}

Thus 
\begin{align*}
\left(\begin{array}{c}
x_{1}\\
u
\end{array}\right) & =\left(\begin{array}{cc}
1 & 0\\
a/\sigma_{I} & (1-a)/\sigma_{I}
\end{array}\right)\left(\begin{array}{c}
x_{1}\\
x_{2}
\end{array}\right);\\
\left(\begin{array}{c}
y_{1}\\
v
\end{array}\right) & =\left(\begin{array}{cc}
1 & 0\\
b/\sigma_{J} & (1-b)/\sigma_{J}
\end{array}\right)\left(\begin{array}{c}
y_{1}\\
y_{2}
\end{array}\right).
\end{align*}

and their respective covariance matrices are
\begin{align*}
\mathbb{C}\left(\begin{array}{c}
x_{1}\\
u
\end{array}\right) & =\left(\begin{array}{cc}
1 & 0\\
a/\sigma_{I} & (1-a)/\sigma_{I}
\end{array}\right)\left(\begin{array}{cc}
s^{2} & \sigma\\
\sigma & S^{2}
\end{array}\right)\left(\begin{array}{cc}
1 & a/\sigma_{I}\\
0 & (1-a)/\sigma_{I}
\end{array}\right)\\
 & =\left(\begin{array}{cc}
s^{2} & \frac{as^{2}+(1-a)\sigma}{\sigma_{I}}\\
\frac{as^{2}+(1-a)\sigma}{\sigma_{I}} & 1
\end{array}\right),
\end{align*}

similarly
\[
\mathbb{C}\left(\begin{array}{c}
y_{1}\\
v
\end{array}\right)=\left(\begin{array}{cc}
s^{2} & \frac{bs^{2}+(1-b)\sigma}{\sigma_{J}}\\
\frac{bs^{2}+(1-b)\sigma}{\sigma_{J}} & 1
\end{array}\right).
\]

Under SGAM, couples have characteristics $\left(\begin{array}{c}
x_{1}\\
t\\
y_{1}\\
t
\end{array}\right),$ where $\left(\begin{array}{c}
x_{1}\\
y_{1}\\
t
\end{array}\right)$ is trivariate normal with mean 0 and covariance matrix
\[
\Sigma=\left(\begin{array}{ccc}
s^{2} & AB & A\\
AB & s^{2} & B\\
A & B & 1
\end{array}\right)
\]
where
\[
A=\frac{as^{2}+(1-a)\sigma}{\sigma_{I}};B=\frac{bs^{2}+(1-b)\sigma}{\sigma_{J}}.
\]

Proof. XXX expand Pierre's note in Computations5short.

Lastly, we calculate the covariance matrix of couples' original characteristics.
Since
\[
\left(\begin{array}{c}
x_{1}\\
x_{2}\\
y_{1}\\
y_{2}
\end{array}\right)=\left(\begin{array}{ccc}
1 & 0 & 0\\
\frac{-a}{1-a} & 0 & \frac{\sigma_{I}}{1-a}\\
0 & 1 & 0\\
0 & \frac{-b}{1-b} & \frac{\sigma_{J}}{1-b}
\end{array}\right)\left(\begin{array}{c}
x_{1}\\
y_{1}\\
t
\end{array}\right)
\]
we have that the mean is again 0 and the covariance matrix is 
\begin{align*}
\mathbb{C}\left(\begin{array}{c}
x_{1}\\
x_{2}\\
y_{1}\\
y_{2}
\end{array}\right) & =\left(\begin{array}{ccc}
1 & 0 & 0\\
\frac{-a}{1-a} & 0 & \frac{\sigma_{I}}{1-a}\\
0 & 1 & 0\\
0 & \frac{-b}{1-b} & \frac{\sigma_{J}}{1-b}
\end{array}\right)\Sigma\left(\begin{array}{cccc}
1 & \frac{-a}{1-a} & 0 & 0\\
0 & 0 & 1 & \frac{-b}{1-b}\\
0 & \frac{\sigma_{I}}{1-a} & 0 & \frac{\sigma_{J}}{1-b}
\end{array}\right)\\
 & =\left(\begin{array}{cccc}
s^{2} & \sigma & AB & AD\\
\sigma & S^{2} & BC & CD\\
AB & BC & s^{2} & \sigma\\
AD & CD & \sigma & S^{2}
\end{array}\right)
\end{align*}
where
\[
C=\frac{a\sigma+(1-a)S^{2}}{\sigma_{I}};D=\frac{b\sigma+(1-b)S^{2}}{\sigma_{J}}.
\]

From the above and \eqref{Chil} we can calculate the
covariance matrix of children's characteristics as
\begin{align*}
\mathbb{C}\left(\begin{array}{c}
x_{1}^{\prime}\\
x_{2}^{\prime}
\end{array}\right) & =\left(\begin{array}{cc}
1 & 0\\
0 & 1
\end{array}\right)+\left(\begin{array}{cccc}
\frac{\tau}{2} & 0 & \frac{\tau}{2} & 0\\
0 & \frac{\theta}{2} & 0 & \frac{\theta}{2}
\end{array}\right)\left(\begin{array}{cccc}
s^{2} & \sigma & AB & AD\\
\sigma & S^{2} & BC & CD\\
AB & BC & s^{2} & \sigma\\
AD & CD & \sigma & S^{2}
\end{array}\right)\left(\begin{array}{cc}
\frac{\tau}{2} & 0\\
0 & \frac{\theta}{2}\\
\frac{\tau}{2} & 0\\
0 & \frac{\theta}{2}
\end{array}\right)\\
 & =\left(\begin{array}{cc}
\frac{\tau^{2}}{2}(s^{2}+AB)+1 & \frac{\tau\theta}{4}(2\sigma+AD+BC)\\
\frac{\tau\theta}{4}(2\sigma+AD+BC) & \frac{\theta^{2}}{2}(S^{2}+CD)+1
\end{array}\right).
\end{align*}

Thus $x_{1}^{\prime}$ and $x_{2}^{\prime}$ will be positively correlated
if $2\sigma+AD+BC>0$. This is always positive if $\sigma>0$; if
$\sigma=0$ it reduces to
\[
\frac{(a+b-2ab)s^{2}S^{2}}{\sigma_{I}\sigma_{J}}
\]
which is positive unless $a=b=0$ or $a=b=1$.

\end{proof}

\begin{proof}[Proof of Claim \ref{prop-gamma}]
Write
\begin{align*}
x_{1}^{\prime}	&=\tau\frac{x_{1}+y_{1}}{2}+\varepsilon \\
x_{2}^{\prime}	&=\gamma x_{1}^{\prime}+\theta\frac{x_{2}+y_{2}}{2}+\eta \\
	              &=\gamma\tau \frac{x_{1}+y_{1}}{2} + \theta \frac{x_{2}+y_{2}}{2} 
	                + \eta + \gamma\varepsilon
\end{align*}

Since
\[
\left(\begin{array}{c}
\tau\frac{x_{1}+y_{1}}{2}\\
\gamma\tau\frac{x_{1}+y_{1}}{2}+\theta\frac{x_{2}+y_{2}}{2}
\end{array}\right)=\left(\begin{array}{cccc}
\frac{\tau}{2} & 0 & \frac{\tau}{2} & 0\\
\frac{\gamma\tau}{2} & \frac{\theta}{2} & \frac{\gamma\tau}{2} & \frac{\theta}{2}
\end{array}\right)\left(\begin{array}{c}
x_{1}\\
x_{2}\\
y_{1}\\
y_{2}
\end{array}\right)
\]
we can use \eqref{cov-couples-SGAM} to derive the covariance matrix for children:

\begin{align*}
\mathbb{C}	&= \left(\begin{array}{cc}
1 & \gamma\\
\gamma & \ 1+\gamma^{2}
\end{array}\right)+\left(\begin{array}{cccc}
\frac{\tau}{2} & 0 & \frac{\tau}{2} & 0\\
\frac{\gamma\tau}{2} & \frac{\theta}{2} & \frac{\gamma\tau}{2} & \frac{\theta}{2}
\end{array}\right)\left(\begin{array}{cccc}
s^{2} & \sigma & A^{2} & AC\\
\sigma & S^{2} & AC & C^{2}\\
A^{2} & AC & s^{2} & \sigma\\
AC & C^{2} & \sigma & S^{2}
\end{array}\right)\left(\begin{array}{cc}
\frac{\tau}{2} & \frac{\gamma\tau}{2}\\
0 & \frac{\theta}{2}\\
\frac{\tau}{2} & \frac{\gamma\tau}{2}\\
0 & \frac{\theta}{2}
\end{array}\right) \\
	&=\left(\begin{array}{cc}
\frac{\tau^{2}}{2}(s^{2}+A^{2})+1 & \frac{\gamma\tau^{2}}{2}(s^{2}+A^{2})+\frac{\tau\theta}{2}(\sigma+AC)+\gamma\\
\frac{\gamma\tau^{2}}{2}(s^{2}+A^{2})+\frac{\tau\theta}{2}(\sigma+AC)+\gamma & \ \ \frac{\gamma^{2}\tau^{2}}{2}(s^{2}+A^{2})+\gamma\tau\theta(\sigma+AC)+\frac{\theta^{2}}{2}(S^{2}+C^{2})+1+\gamma^{2}
\end{array}\right)
\end{align*}

The claims in the proof now follow from the covariance:
\[
\frac{\gamma\tau^{2}}{2}(s^{2}+A^{2})+\frac{\tau\theta}{2}(\sigma+AC)+\gamma
\]
This is positive if any of $\sigma > 0$, $\gamma > 0$,  or $AC > 0$ 
(which holds if $0 < a < 1$ when $\sigma = 0$).


\end{proof}

\begin{proof}[Proof of Proposition \ref{prop-non-normal}]
The correlation is signed by the covariance. Write $C$ for the set of couples
in the parents' generation with typical member $c = (x,y)$. Without loss of generality
let $x_1 \ge y_1$. Then, since the iso-attractiveness curves defined by 
$f$ are downward-sloping, $x_2 \le y_2$.

Since $Ex = Ey = 0$, the covariance among the parents' generation is

\[
\int_C (x_1x_2 + y_1y_2)/2 \ dc
\]

Write

\begin{align*}
x^\prime_1 =& \tau x^*_1 + \varepsilon & \textrm{where } x^*_1 =& (x_1+y_1)/2  \\
x^\prime_2 =& \theta x^*_2 + \eta & \textrm{where } x^*_2 =& (x_2+y_2)/2  
\end{align*}

and write the children's covariance as
\[
Cov(x^\prime_1, x^\prime_2) = Cov(\tau x^*_1, \theta x^*_2) + Cov(\tau x^*_1, \eta) + 
  Cov(\varepsilon, \theta x^*_2) + Cov(\varepsilon, \eta).
\]
By independence of the shocks, the last 3 terms are zero. So we need to
show that
\[
Cov(\tau x^*_1, \theta x^*_2) = \tau\theta Cov(x^*_1, x^*_2) > 0
\]

Write
\[
Cov(x^*_1, x^*_2) = \int_C x^*_1 x^*_2 \ dc
\]
using that $Ex^*_1 = Ex^*_2 = 0$. 

Take a typical parent, and write
\begin{align*}
x_1x_2 = (x^*_1 - \Delta_1)(x^*_2 - \Delta_2) \\
y_1y_2 = (x^*_1 + \Delta_1)(x^*_2 + \Delta_2)
\end{align*}
where 
\[
\Delta_1 = (x_1 - y_1)/2;\ \Delta_2 = (x_2 - y_2)/2.
\]
By assumption $\Delta_1 \ge 0$ and $\Delta_2 \le 0$. Furthermore, if $a \in (0,1)$, then
for a set of positive measure, $\Delta_1 > 0$ and $\Delta_2 < 0$, by our assumption 
that not all matching couples are identical.

Taking the average of the parents gives
\[
(x_1x_2 + y_1y_2)/2 = x^*_1x^*_2 + \Delta_1\Delta_2
\]
and if $a \in (0,1)$, this is strictly less than $x^*_1x^*_2$ for a set of 
positive measure. Plugging this into the integral gives

\[
Cov(x_1,x_2) \le Cov(x^*_1, x^*_2) = \int_C x^*_1 x^*_2 \ dc
\]
with strict inequality if $a \in (0,1)$. Since the parental covariance was 0
by assumption, this completes the proof.

\end{proof}




